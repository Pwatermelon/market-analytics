"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è Wildberries - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç API –∏ Selenium
"""
from typing import List, Dict, Optional
from datetime import datetime
import re
import json
import time
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import undetected_chromedriver as uc
from .base_parser import BaseParser


class WildberriesParser(BaseParser):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è Wildberries —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Selenium"""
    
    def __init__(self):
        super().__init__()
        self.driver = None
        self.session = None
        if requests:
            self.session = requests.Session()
            self.session.headers.update({
                'User-Agent': self.ua.random,
                'Accept': 'application/json, text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            })
        self._init_driver()
    
    def _init_driver(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ —Å –æ–±—Ö–æ–¥–æ–º –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        try:
            options = Options()
            options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            options.add_argument(f'user-agent={self.ua.random}')
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º undetected-chromedriver –¥–ª—è –æ–±—Ö–æ–¥–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
            self.driver = uc.Chrome(options=options, version_main=None)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π Chrome
            try:
                options = Options()
                options.add_argument('--headless=new')
                options.add_argument('--no-sandbox')
                options.add_argument('--disable-dev-shm-usage')
                self.driver = webdriver.Chrome(options=options)
            except Exception as e2:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Chrome: {e2}")
                self.driver = None
    
    def _extract_article(self, url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞ –∏–∑ URL"""
        # –§–æ—Ä–º–∞—Ç—ã: 
        # /catalog/12345678/detail.aspx
        # /catalog/12345678/
        # /catalog/12345678
        match = re.search(r'/catalog/(\d+)(?:/|$)', url)
        if match:
            return match.group(1)
        return None
    
    def _wait_for_page_load(self, timeout: int = 30):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            WebDriverWait(self.driver, timeout).until(
                lambda d: d.execute_script('return document.readyState') == 'complete'
            )
            time.sleep(2)  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è JavaScript
        except TimeoutException:
            pass
    
    def _scroll_to_load_reviews(self, max_scrolls: int = 5):
        """–ü—Ä–æ–∫—Ä—É—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–∑—ã–≤–æ–≤"""
        for _ in range(max_scrolls):
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 2))
            self.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.5)
    
    def get_product_name(self, url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"""
        if not self.driver:
            return None
        
        try:
            self.driver.get(url)
            self._wait_for_page_load()
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è
            selectors = [
                'h1.product-page__title',
                'h1[data-link="text{:product^goodsName}"]',
                'h1',
                '.product-page__header h1',
                '[data-link="text{:product^goodsName}"]'
            ]
            
            for selector in selectors:
                try:
                    element = WebDriverWait(self.driver, 5).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                    )
                    name = element.text.strip()
                    if name:
                        return name
                except:
                    continue
            
            return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞: {e}")
            return None
    
    def parse_reviews(self, url: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ - —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º API, –ø–æ—Ç–æ–º Selenium"""
        article = self._extract_article(url)
        if not article:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—Ä—Ç–∏–∫—É–ª –∏–∑ URL")
            return []
        
        # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ API –æ—Ç–∑—ã–≤–æ–≤
        api_reviews = self._try_api_method(article)
        if api_reviews and len(api_reviews) > 0:
            print(f"‚úÖ API –º–µ—Ç–æ–¥ –≤–µ—Ä–Ω—É–ª {len(api_reviews)} –æ—Ç–∑—ã–≤–æ–≤")
            return api_reviews
        
        # –ï—Å–ª–∏ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º Selenium
        print("üîÑ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Selenium...")
        return self._parse_with_selenium(url, article)
    
    def _try_api_method(self, article: str) -> List[Dict]:
        """–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ API"""
        reviews = []
        
        if not self.session or not requests:
            return reviews
        
        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ –Ω–µ–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π API
            api_url = "https://feedbacks1.wildberries.ru/api/v1/summary/full"
            
            params = {
                'nmId': article,
                'skip': 0,
                'take': 100
            }
            
            headers = {
                'Referer': f'https://www.wildberries.ru/catalog/{article}/detail.aspx'
            }
            
            response = self.session.get(api_url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    if 'feedbacks' in data:
                        for feedback in data['feedbacks']:
                            try:
                                review_text = feedback.get('text', '')
                                if not review_text or len(review_text) < 10:
                                    continue
                                
                                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                                date_str = feedback.get('createdDate', '')
                                date = datetime.now()
                                if date_str:
                                    try:
                                        date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                                    except:
                                        pass
                                
                                reviews.append({
                                    "author": feedback.get('wbUserDetails', {}).get('name', '–ê–Ω–æ–Ω–∏–º'),
                                    "rating": feedback.get('productValuation', 0),
                                    "text": review_text,
                                    "date": date
                                })
                            except Exception as e:
                                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–∞ –∏–∑ API: {e}")
                                continue
                except json.JSONDecodeError:
                    pass
        except Exception as e:
            print(f"‚ö†Ô∏è API –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        
        return reviews
    
    def _parse_with_selenium(self, url: str, article: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Selenium"""
        if not self.driver:
            return []
        
        reviews = []
        
        try:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤
            feedback_url = f"https://www.wildberries.ru/catalog/{article}/feedbacks"
            print(f"üåê –û—Ç–∫—Ä—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤: {feedback_url}")
            
            self.driver.get(feedback_url)
            self._wait_for_page_load()
            time.sleep(5)
            
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            print("üìú –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
            for i in range(10):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # –ò—â–µ–º –∫–Ω–æ–ø–∫–∏ "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â–µ"
                try:
                    buttons = self.driver.find_elements(By.TAG_NAME, "button")
                    for btn in buttons:
                        try:
                            if not btn.is_displayed():
                                continue
                            btn_text = btn.text.lower()
                            if any(word in btn_text for word in ["–ø–æ–∫–∞–∑–∞—Ç—å", "–∑–∞–≥—Ä—É–∑–∏—Ç—å", "–µ—â–µ", "–µ—â—ë"]):
                                self.driver.execute_script("arguments[0].click();", btn)
                                print(f"‚úÖ –ö–ª–∏–∫–Ω—É–ª: {btn.text}")
                                time.sleep(3)
                        except:
                            continue
                except:
                    pass
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            reviews = self._parse_html_reviews(soup)
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ Selenium: {e}")
            import traceback
            print(traceback.format_exc())
        
        return reviews
    
    def _parse_html_reviews(self, soup: BeautifulSoup) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ HTML"""
        reviews = []
        seen_texts = set()
        
        # –ò—â–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –æ—Ç–∑—ã–≤–æ–≤
        selectors = [
            'div[class*="feedback"]',
            'div[class*="review"]',
            'div[class*="comment"]',
            '[data-feedback-id]',
            'article',
            '.feedback-item',
            '.review-item'
        ]
        
        containers = []
        for selector in selectors:
            try:
                elements = soup.select(selector)
                containers.extend(elements)
            except:
                continue
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(containers)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤")
        
        for container in containers:
            try:
                text = container.get_text(separator=' ', strip=True)
                
                if len(text) < 30:
                    continue
                
                # –û—á–∏—â–∞–µ–º –æ—Ç —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                lines = text.split('\n')
                clean_lines = []
                for line in lines:
                    line = line.strip()
                    if len(line) > 15 and not any(skip in line.lower() for skip in 
                        ['–æ—Ç–∑—ã–≤', '–æ—Ü–µ–Ω–∫–∞', '—Ä–µ–π—Ç–∏–Ω–≥', 'cookie', '–ø–æ–ª–∏—Ç–∏–∫–∞', '—Å–æ–≥–ª–∞—Å–∏–µ']):
                        clean_lines.append(line)
                
                review_text = ' '.join(clean_lines)
                
                if len(review_text) < 20:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                text_hash = hash(review_text[:100])
                if text_hash in seen_texts:
                    continue
                seen_texts.add(text_hash)
                
                # –ê–≤—Ç–æ—Ä
                author = "–ê–Ω–æ–Ω–∏–º"
                author_elem = container.find(['strong', 'b', 'span'], 
                    class_=lambda x: x and ('author' in str(x).lower() or 'user' in str(x).lower()))
                if not author_elem:
                    author_elem = container.find(['strong', 'b'])
                if author_elem:
                    author = author_elem.get_text(strip=True)
                    if len(author) > 50:
                        author = "–ê–Ω–æ–Ω–∏–º"
                
                # –†–µ–π—Ç–∏–Ω–≥
                rating = 0
                stars = container.find_all(['span', 'div', 'i'], 
                    class_=lambda x: x and 'star' in str(x).lower())
                if stars:
                    filled = [s for s in stars if 'fill' in str(s.get('class', [])).lower() 
                             or 'active' in str(s.get('class', [])).lower()]
                    rating = len(filled)
                
                if not rating:
                    rating_match = re.search(r'(\d+)\s*(–∑–≤–µ–∑–¥|star|‚≠ê)', container.get_text(), re.IGNORECASE)
                    if rating_match:
                        rating = int(rating_match.group(1))
                
                # –î–∞—Ç–∞
                date = datetime.now()
                date_elem = container.find(['time', 'span', 'div'], 
                    class_=lambda x: x and 'date' in str(x).lower())
                if not date_elem:
                    date_elem = container.find('time')
                if date_elem:
                    date_text = date_elem.get_text(strip=True) or date_elem.get('datetime', '')
                    if date_text:
                        date = self._parse_date(date_text)
                
                reviews.append({
                    "author": author,
                    "rating": rating,
                    "text": review_text,
                    "date": date
                })
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {e}")
                continue
        
        return reviews
    
    def parse_reviews_old(self, url: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ —Å Wildberries –Ω–∞–ø—Ä—è–º—É—é —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        if not self.driver:
            return []
        
        reviews = []
        
        try:
            print("üåê –û—Ç–∫—Ä—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞...")
            self.driver.get(url)
            self._wait_for_page_load()
            time.sleep(5)  # –î–∞–µ–º –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            try:
                with open('/tmp/wb_page_before.html', 'w', encoding='utf-8') as f:
                    f.write(self.driver.page_source)
                print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ /tmp/wb_page_before.html")
            except:
                pass
            
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –∫ –Ω–∞—á–∞–ª—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            self.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(2)
            
            # –ò—â–µ–º –≤–∫–ª–∞–¥–∫—É "–û—Ç–∑—ã–≤—ã" –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
            print("üîç –ò—â—É –≤–∫–ª–∞–¥–∫—É —Å –æ—Ç–∑—ã–≤–∞–º–∏...")
            feedback_clicked = False
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–∫–ª–∞–¥–∫–æ–π –æ—Ç–∑—ã–≤–æ–≤
            all_clickable = self.driver.find_elements(By.CSS_SELECTOR, "a, button, div[role='button'], span[role='button']")
            
            for element in all_clickable:
                try:
                    text = element.text.lower()
                    href = element.get_attribute("href") or ""
                    onclick = element.get_attribute("onclick") or ""
                    data_link = element.get_attribute("data-link") or ""
                    
                    # –ò—â–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    if any(word in text for word in ["–æ—Ç–∑—ã–≤", "feedback", "–æ—Ç–∑—ã–≤—ã", "feedbacks"]) or \
                       "feedback" in href.lower() or "feedback" in onclick.lower() or "feedback" in data_link.lower():
                        print(f"üéØ –ù–∞—à–µ–ª –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –≤–∫–ª–∞–¥–∫—É: {element.text[:50]} | href={href[:50]}")
                        try:
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                            time.sleep(1)
                            self.driver.execute_script("arguments[0].click();", element)
                            print("‚úÖ –ö–ª–∏–∫–Ω—É–ª –Ω–∞ –≤–∫–ª–∞–¥–∫—É –æ—Ç–∑—ã–≤–æ–≤")
                            time.sleep(5)
                            feedback_clicked = True
                            break
                        except Exception as e:
                            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å: {e}")
                            continue
                except:
                    continue
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤–∫–ª–∞–¥–∫—É, –ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞–ø—Ä—è–º—É—é –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤
            if not feedback_clicked:
                print("üîÑ –ü—Ä–æ–±—É—é –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞–ø—Ä—è–º—É—é...")
                article = self._extract_article(url)
                if article:
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã URL –æ—Ç–∑—ã–≤–æ–≤
                    feedback_urls = [
                        f"https://www.wildberries.ru/catalog/{article}/feedbacks",
                        f"https://www.wildberries.ru/catalog/{article}/detail.aspx?tab=feedbacks",
                        f"https://www.wildberries.ru/catalog/{article}/detail.aspx#feedbacks",
                        f"https://www.wildberries.ru/catalog/{article}/detail.aspx?tab=reviews",
                    ]
                    
                    for feedback_url in feedback_urls:
                        try:
                            print(f"üîó –ü—Ä–æ–±—É—é URL: {feedback_url}")
                            self.driver.get(feedback_url)
                            self._wait_for_page_load()
                            time.sleep(5)
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ—Ç–∑—ã–≤—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                            page_text = self.driver.page_source.lower()
                            if "–æ—Ç–∑—ã–≤" in page_text or "feedback" in page_text:
                                print(f"‚úÖ –ü–µ—Ä–µ—à–µ–ª –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤: {feedback_url}")
                                break
                        except Exception as e:
                            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –Ω–∞ {feedback_url}: {e}")
                            continue
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            print("‚è≥ –ñ–¥—É –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
            time.sleep(5)
            
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–∑—ã–≤–æ–≤
            print("üìú –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–∑—ã–≤–æ–≤...")
            last_review_count = 0
            no_change_iterations = 0
            
            for i in range(20):
                # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –≤–Ω–∏–∑
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                time.sleep(1)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ —á–µ—Ä–µ–∑ JS
                current_count = self.driver.execute_script("""
                    return document.querySelectorAll('[class*="feedback"], [data-feedback-id], article').length;
                """)
                
                if current_count > last_review_count:
                    last_review_count = current_count
                    no_change_iterations = 0
                    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ—Ç–∑—ã–≤–æ–≤: {current_count}")
                else:
                    no_change_iterations += 1
                
                # –ò—â–µ–º –∏ –∫–ª–∏–∫–∞–µ–º –∫–Ω–æ–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
                try:
                    buttons = self.driver.find_elements(By.TAG_NAME, "button")
                    for btn in buttons:
                        try:
                            if not btn.is_displayed():
                                continue
                            btn_text = btn.text.lower()
                            if any(word in btn_text for word in ["–ø–æ–∫–∞–∑–∞—Ç—å", "–∑–∞–≥—Ä—É–∑–∏—Ç—å", "–µ—â–µ", "more", "–µ—â—ë", "–ø–æ–∫–∞–∑–∞—Ç—å –µ—â–µ"]):
                                self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", btn)
                                time.sleep(0.5)
                                self.driver.execute_script("arguments[0].click();", btn)
                                print(f"‚úÖ –ö–ª–∏–∫–Ω—É–ª: {btn.text}")
                                time.sleep(4)
                                no_change_iterations = 0  # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞
                        except:
                            continue
                except:
                    pass
                
                # –ï—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º –ø—Ä–æ–∫—Ä—É—Ç–∏—Ç—å –≤–≤–µ—Ä—Ö-–≤–Ω–∏–∑
                if no_change_iterations >= 3:
                    self.driver.execute_script("window.scrollTo(0, 0);")
                    time.sleep(1)
                    self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(2)
                
                # –ï—Å–ª–∏ 5 —Ä–∞–∑ –ø–æ–¥—Ä—è–¥ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å - –≤—ã—Ö–æ–¥–∏–º
                if no_change_iterations >= 5:
                    print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–Ω–µ—Ç –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
                    break
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π HTML
            try:
                with open('/tmp/wb_page_after.html', 'w', encoding='utf-8') as f:
                    f.write(self.driver.page_source)
                print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π HTML –≤ /tmp/wb_page_after.html")
            except:
                pass
            
            # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ JavaScript
            print("üîç –ü—Ä–æ–±—É—é –∏–∑–≤–ª–µ—á—å –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ JavaScript...")
            js_reviews = self._extract_reviews_via_js()
            if js_reviews:
                print(f"‚úÖ JavaScript –º–µ—Ç–æ–¥ –Ω–∞—à–µ–ª {len(js_reviews)} –æ—Ç–∑—ã–≤–æ–≤")
                reviews = js_reviews
            else:
                # –ü–∞—Ä—Å–∏–º –æ—Ç–∑—ã–≤—ã –∏–∑ HTML
                print("üîç –ü–∞—Ä—Å—é –æ—Ç–∑—ã–≤—ã –∏–∑ HTML...")
                page_source = self.driver.page_source
                
                # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                print(f"üìÑ –†–∞–∑–º–µ—Ä HTML: {len(page_source)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"üìä –°–æ–¥–µ—Ä–∂–∏—Ç '–æ—Ç–∑—ã–≤': {'–æ—Ç–∑—ã–≤' in page_source.lower()}")
                print(f"üìä –°–æ–¥–µ—Ä–∂–∏—Ç 'feedback': {'feedback' in page_source.lower()}")
                
                soup = BeautifulSoup(page_source, 'html.parser')
                reviews = self._parse_from_html_improved(soup)
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
                if len(reviews) == 0:
                    print("üîÑ –ü—Ä–æ–±—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
                    reviews = self._parse_alternative_method(soup)
            
            print(f"‚úÖ –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–∑—ã–≤–æ–≤ Wildberries: {e}")
            import traceback
            print(traceback.format_exc())
        
        return reviews
    
    
    def _parse_from_html_improved(self, soup: BeautifulSoup) -> List[Dict]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ - –∏—â–µ—Ç –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º"""
        reviews = []
        
        # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—Ç–∑—ã–≤—ã
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º, data-–∞—Ç—Ä–∏–±—É—Ç–∞–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        
        # 1. –ò—â–µ–º –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∫–ª–∞—Å—Å–∞–º WB
        review_containers = []
        
        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –æ—Ç–∑—ã–≤–æ–≤
        container_selectors = [
            'div[class*="feedback"]',
            'div[class*="review"]',
            'div[class*="comment"]',
            'article[class*="feedback"]',
            '[data-feedback-id]',
            '[id*="feedback"]',
            '[id*="review"]'
        ]
        
        for selector in container_selectors:
            try:
                elements = soup.select(selector)
                review_containers.extend(elements)
            except:
                continue
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(review_containers)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –æ—Ç–∑—ã–≤–æ–≤")
        
        # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º, –∏—â–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ - –∏—â–µ–º div —Å —Ç–µ–∫—Å—Ç–æ–º –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –æ—Ç–∑—ã–≤
        if not review_containers:
            print("üîç –ò—â—É –æ—Ç–∑—ã–≤—ã –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ç–µ–∫—Å—Ç–∞...")
            all_divs = soup.find_all('div')
            for div in all_divs:
                text = div.get_text(strip=True)
                # –û—Ç–∑—ã–≤ –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                if len(text) > 50 and text.count('.') >= 1:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —Ä—è–¥–æ–º —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —É–∫–∞–∑—ã–≤–∞—é—â–∏—Ö –Ω–∞ –æ—Ç–∑—ã–≤
                    parent = div.parent
                    if parent:
                        parent_text = parent.get_text(strip=True).lower()
                        if any(word in parent_text for word in ['–æ—Ç–∑—ã–≤', 'feedback', '–æ—Ü–µ–Ω–∫–∞', '—Ä–µ–π—Ç–∏–Ω–≥']):
                            review_containers.append(div)
        
        print(f"üì¶ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(review_containers)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤")
        
        # 3. –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        seen_texts = set()
        for container in review_containers:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                full_text = container.get_text(separator=' ', strip=True)
                
                # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ (—Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ)
                paragraphs = container.find_all(['p', 'div', 'span'])
                review_text = ""
                for p in paragraphs:
                    p_text = p.get_text(strip=True)
                    if len(p_text) > len(review_text) and len(p_text) > 30:
                        review_text = p_text
                
                if not review_text or len(review_text) < 20:
                    review_text = full_text
                
                # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                lines = review_text.split('\n')
                clean_lines = []
                for line in lines:
                    line = line.strip()
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ
                    if len(line) > 15 and not any(skip in line.lower() for skip in ['–æ—Ç–∑—ã–≤', '–æ—Ü–µ–Ω–∫–∞', '—Ä–µ–π—Ç–∏–Ω–≥', '–∑–≤–µ–∑–¥', '‚≠ê']):
                        clean_lines.append(line)
                
                review_text = ' '.join(clean_lines)
                
                if len(review_text) < 20:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
                text_hash = hash(review_text[:100])
                if text_hash in seen_texts:
                    continue
                seen_texts.add(text_hash)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞
                author = "–ê–Ω–æ–Ω–∏–º"
                author_elem = container.find(['strong', 'b', 'span'], class_=lambda x: x and ('author' in str(x).lower() or 'user' in str(x).lower()))
                if not author_elem:
                    author_elem = container.find(['strong', 'b'])
                if author_elem:
                    author = author_elem.get_text(strip=True)
                    if len(author) > 50:  # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ - –Ω–µ –∏–º—è
                        author = "–ê–Ω–æ–Ω–∏–º"
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                rating = 0
                # –ò—â–µ–º –∑–≤–µ–∑–¥—ã
                stars = container.find_all(['span', 'div', 'i'], class_=lambda x: x and 'star' in str(x).lower())
                if stars:
                    rating = len([s for s in stars if 'fill' in str(s.get('class', [])).lower() or 'active' in str(s.get('class', [])).lower()])
                
                # –ò—â–µ–º —á–∏—Å–ª–æ —Ä–µ–π—Ç–∏–Ω–≥–∞
                if not rating:
                    rating_match = re.search(r'(\d+)\s*(–∑–≤–µ–∑–¥|star|‚≠ê)', container.get_text(), re.IGNORECASE)
                    if rating_match:
                        rating = int(rating_match.group(1))
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
                date = datetime.now()
                date_elem = container.find(['time', 'span', 'div'], class_=lambda x: x and 'date' in str(x).lower())
                if not date_elem:
                    date_elem = container.find('time')
                if date_elem:
                    date_text = date_elem.get_text(strip=True) or date_elem.get('datetime', '')
                    if date_text:
                        date = self._parse_date(date_text)
                
                reviews.append({
                    "author": author,
                    "rating": rating,
                    "text": review_text,
                    "date": date
                })
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {e}")
                continue
        
        print(f"‚úÖ –†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(reviews)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤")
        return reviews
    
    def _parse_alternative_method(self, soup: BeautifulSoup) -> List[Dict]:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –∏—â–µ–º –ª—é–±–æ–π —Ç–µ–∫—Å—Ç, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –æ—Ç–∑—ã–≤"""
        reviews = []
        
        print("üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥: –∏—â—É –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –æ—Ç–∑—ã–≤...")
        
        # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª–∏–Ω–Ω–µ–µ 50 —Å–∏–º–≤–æ–ª–æ–≤
        all_elements = soup.find_all(['div', 'p', 'span', 'article', 'section'])
        
        for elem in all_elements:
            try:
                text = elem.get_text(separator=' ', strip=True)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ
                if len(text) < 50 or len(text) > 2000:
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
                if any(skip in text.lower() for skip in ['cookie', '–∫—É–∫–∏', '—Å–æ–≥–ª–∞—Å–∏–µ', '–ø–æ–ª–∏—Ç–∏–∫–∞', 'copyright']):
                    continue
                
                # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç–∑—ã–≤–∞–º–∏
                # –û—Ç–∑—ã–≤ –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                sentences = text.split('.')
                if len(sentences) < 2:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä—è–¥–æ–º —ç–ª–µ–º–µ–Ω—Ç—ã, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –æ—Ç–∑—ã–≤
                parent = elem.parent
                if parent:
                    parent_html = str(parent).lower()
                    if any(word in parent_html for word in ['feedback', '–æ—Ç–∑—ã–≤', 'review', 'comment']):
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                        author = "–ê–Ω–æ–Ω–∏–º"
                        rating = 0
                        date = datetime.now()
                        
                        # –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
                        author_elem = parent.find(['strong', 'b', 'span'], string=re.compile(r'[–ê-–Ø–Å][–∞-—è—ë]+'))
                        if author_elem:
                            author = author_elem.get_text(strip=True)
                        
                        # –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                        rating_match = re.search(r'(\d+)\s*(–∑–≤–µ–∑–¥|star)', parent_html)
                        if rating_match:
                            rating = int(rating_match.group(1))
                        
                        reviews.append({
                            "author": author,
                            "rating": rating,
                            "text": text,
                            "date": date
                        })
            except:
                continue
        
        print(f"üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º –º–µ—Ç–æ–¥–æ–º –Ω–∞–π–¥–µ–Ω–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤")
        return reviews
    
    def _parse_from_html(self, soup: BeautifulSoup) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ HTML - –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è WB"""
        reviews = []
        
        # –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ Wildberries
        review_selectors = [
            'div.feedback__item',
            'div[class*="feedback__item"]',
            'div[data-feedback-id]',
            'article.feedback',
            'div.feedback',
            '[class*="FeedbackItem"]',
            '[class*="feedback-item"]'
        ]
        
        all_elements = []
        for selector in review_selectors:
            try:
                elements = soup.select(selector)
                if elements:
                    all_elements.extend(elements)
                    print(f"‚úÖ –ù–∞—à–µ–ª {len(elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä—É: {selector}")
            except:
                continue
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º, –∏—â–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        if not all_elements:
            print("üîç –ò—â—É –æ—Ç–∑—ã–≤—ã –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            # –ò—â–µ–º –≤—Å–µ div —Å —Ç–µ–∫—Å—Ç–æ–º, –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –æ—Ç–∑—ã–≤—ã
            all_divs = soup.find_all('div', class_=lambda x: x and ('feedback' in x.lower() or 'review' in x.lower() or 'comment' in x.lower()))
            all_elements.extend(all_divs)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É
        seen_texts = set()
        unique_elements = []
        for elem in all_elements:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
            elem_text = elem.get_text(strip=True)
            if len(elem_text) > 20:  # –ú–∏–Ω–∏–º—É–º 20 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ—Ç–∑—ã–≤–∞
                text_hash = hash(elem_text[:100])  # –•–µ—à –ø–µ—Ä–≤—ã—Ö 100 —Å–∏–º–≤–æ–ª–æ–≤
                if text_hash not in seen_texts:
                    seen_texts.add(text_hash)
                    unique_elements.append(elem)
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(unique_elements)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ—Ç–∑—ã–≤–æ–≤")
        
        for element in unique_elements:
            try:
                # –¢–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ - –∏—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
                text = ""
                
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞
                text_candidates = [
                    element.select_one('.feedback__text'),
                    element.select_one('[class*="text"]'),
                    element.select_one('[class*="content"]'),
                    element.select_one('p'),
                    element.select_one('div[class*="description"]'),
                ]
                
                for text_elem in text_candidates:
                    if text_elem:
                        text = text_elem.get_text(strip=True)
                        if len(text) > 20:
                            break
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –±–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
                if not text or len(text) < 20:
                    text = element.get_text(strip=True)
                    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ (–∞–≤—Ç–æ—Ä, –¥–∞—Ç–∞, —Ä–µ–π—Ç–∏–Ω–≥)
                    lines = text.split('\n')
                    text_lines = []
                    for line in lines:
                        line = line.strip()
                        if len(line) > 10 and not any(word in line.lower() for word in ['–æ—Ç–∑—ã–≤', '–æ—Ü–µ–Ω–∫–∞', '—Ä–µ–π—Ç–∏–Ω–≥', '–∑–≤–µ–∑–¥']):
                            text_lines.append(line)
                    text = ' '.join(text_lines)
                
                if not text or len(text) < 20:
                    continue
                
                # –ê–≤—Ç–æ—Ä
                author = "–ê–Ω–æ–Ω–∏–º"
                author_candidates = [
                    element.select_one('.feedback__author'),
                    element.select_one('[class*="author"]'),
                    element.select_one('[class*="user"]'),
                    element.select_one('strong'),
                    element.select_one('b'),
                    element.select_one('[class*="name"]')
                ]
                
                for author_elem in author_candidates:
                    if author_elem:
                        author_text = author_elem.get_text(strip=True)
                        if author_text and len(author_text) < 50:  # –ò–º—è –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º
                            author = author_text
                            break
                
                # –†–µ–π—Ç–∏–Ω–≥ - –∏—â–µ–º –∑–≤–µ–∑–¥—ã –∏–ª–∏ —á–∏—Å–ª–æ
                rating = 0
                
                # –ò—â–µ–º –ø–æ –∫–ª–∞—Å—Å–∞–º –∑–≤–µ–∑–¥
                stars = element.select('.star, .star-filled, .active, [class*="star"]')
                if stars:
                    rating = len([s for s in stars if 'filled' in str(s.get('class', [])) or 'active' in str(s.get('class', []))])
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∑–≤–µ–∑–¥—ã, –∏—â–µ–º —á–∏—Å–ª–æ
                if not rating:
                    rating_elem = element.select_one('[class*="rating"], [data-rating]')
                    if rating_elem:
                        rating_text = rating_elem.get_text(strip=True)
                        rating_match = re.search(r'(\d+)', rating_text)
                        if rating_match:
                            rating = int(rating_match.group(1))
                
                # –î–∞—Ç–∞
                date = datetime.now()
                date_elem = element.select_one('time, [class*="date"], [datetime]')
                if date_elem:
                    date_text = date_elem.get_text(strip=True)
                    if not date_text:
                        date_text = date_elem.get('datetime', '')
                    if date_text:
                        date = self._parse_date(date_text)
                
                reviews.append({
                    "author": author,
                    "rating": rating,
                    "text": text,
                    "date": date
                })
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ –æ—Ç–∑—ã–≤–∞: {e}")
                continue
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É
        unique_reviews = []
        seen_texts = set()
        for review in reviews:
            text_hash = hash(review["text"][:100])
            if text_hash not in seen_texts:
                seen_texts.add(text_hash)
                unique_reviews.append(review)
        
        print(f"‚úÖ –†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(unique_reviews)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ HTML")
        return unique_reviews
    
    def _extract_reviews_via_js(self) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ —á–µ—Ä–µ–∑ JavaScript –Ω–∞–ø—Ä—è–º—É—é –∏–∑ DOM"""
        reviews = []
        try:
            # JavaScript –∫–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤
            js_code = """
            (function() {
                const reviews = [];
                
                // –ò—â–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –æ—Ç–∑—ã–≤–æ–≤
                const selectors = [
                    '.feedback__item',
                    '[class*="feedback"]',
                    '[data-feedback-id]',
                    '[id*="feedback"]',
                    'article',
                    'div[class*="review"]'
                ];
                
                let elements = [];
                for (let selector of selectors) {
                    try {
                        const found = document.querySelectorAll(selector);
                        elements.push(...Array.from(found));
                    } catch(e) {}
                }
                
                // –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                elements = Array.from(new Set(elements));
                
                for (let elem of elements) {
                    try {
                        const text = elem.innerText || elem.textContent || '';
                        
                        // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
                        if (text.length < 30) continue;
                        
                        // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ
                        if (text.toLowerCase().includes('cookie') || 
                            text.toLowerCase().includes('–ø–æ–ª–∏—Ç–∏–∫–∞') ||
                            text.toLowerCase().includes('—Å–æ–≥–ª–∞—Å–∏–µ')) continue;
                        
                        // –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞
                        let author = '–ê–Ω–æ–Ω–∏–º';
                        const authorElem = elem.querySelector('strong, b, [class*="author"], [class*="user"]');
                        if (authorElem) {
                            author = (authorElem.innerText || authorElem.textContent || '').trim();
                            if (author.length > 50) author = '–ê–Ω–æ–Ω–∏–º';
                        }
                        
                        // –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                        let rating = 0;
                        const stars = elem.querySelectorAll('[class*="star"], .star, [class*="rating"]');
                        if (stars.length > 0) {
                            rating = stars.length;
                        } else {
                            const ratingMatch = text.match(/(\\d+)\\s*(–∑–≤–µ–∑–¥|star|‚≠ê)/i);
                            if (ratingMatch) {
                                rating = parseInt(ratingMatch[1]);
                            }
                        }
                        
                        // –ò—â–µ–º –¥–∞—Ç—É
                        let dateText = '';
                        const dateElem = elem.querySelector('time, [class*="date"]');
                        if (dateElem) {
                            dateText = dateElem.getAttribute('datetime') || dateElem.innerText || '';
                        }
                        
                        // –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                        let cleanText = text;
                        const lines = cleanText.split('\\n');
                        cleanText = lines.filter(line => {
                            line = line.trim();
                            return line.length > 10 && 
                                   !line.toLowerCase().includes('–æ—Ç–∑—ã–≤') &&
                                   !line.toLowerCase().includes('–æ—Ü–µ–Ω–∫–∞') &&
                                   !line.toLowerCase().includes('—Ä–µ–π—Ç–∏–Ω–≥');
                        }).join(' ').trim();
                        
                        if (cleanText.length > 20) {
                            reviews.push({
                                author: author,
                                rating: rating,
                                text: cleanText,
                                date: dateText || new Date().toISOString()
                            });
                        }
                    } catch(e) {
                        console.error('Error parsing element:', e);
                    }
                }
                
                return reviews;
            })();
            """
            
            result = self.driver.execute_script(js_code)
            if result:
                for item in result:
                    try:
                        date = datetime.now()
                        if item.get('date'):
                            date = self._parse_date(item['date'])
                        
                        reviews.append({
                            "author": item.get('author', '–ê–Ω–æ–Ω–∏–º'),
                            "rating": item.get('rating', 0),
                            "text": item.get('text', ''),
                            "date": date
                        })
                    except:
                        continue
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ JavaScript –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
        
        return reviews
    
    def _parse_date(self, date_text: str) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –†–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
            patterns = [
                r'(\d{1,2})\.(\d{1,2})\.(\d{4})',  # 26.11.2024
                r'(\d{4})-(\d{2})-(\d{2})',  # 2024-11-26
                r'(\d{1,2})\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})',  # 26 –Ω–æ—è–±—Ä—è 2024
            ]
            
            months = {
                '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
                '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
                '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
            }
            
            for pattern in patterns:
                match = re.search(pattern, date_text.lower())
                if match:
                    if len(match.groups()) == 3:
                        if match.group(2) in months:
                            day, month_name, year = match.groups()
                            month = months[month_name]
                            return datetime(int(year), month, int(day))
                        else:
                            parts = list(match.groups())
                            if len(parts[0]) == 4:  # YYYY-MM-DD
                                return datetime(int(parts[0]), int(parts[1]), int(parts[2]))
                            else:  # DD.MM.YYYY
                                return datetime(int(parts[2]), int(parts[1]), int(parts[0]))
        except:
            pass
        
        return datetime.now()
    
    def __del__(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass

